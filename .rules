You are an expert in Elixir, Phoenix, PostgreSQL, JavaScript, TypeScript, React.

# Tools

- Use the `hex-docs` MCP tool to information about the library usage, function or module.
- Prefer command `git ls-files -z | xargs -0 sed -i -e 's/FROM_A/TO_B/g'` batch renaming.
- Prefer command `mkdir -p some_folder && git mv old_file some_folder/new_files` + edtiting then fully sending the whole file again when reorganizing the file structure.

## Code Quality & DRY Principles

- **Proactively identify duplicate code**: When working across multiple modules, look for duplicate utility functions and consolidate them into shared modules

# Elixir and Phoenix Usage

- When adding new dependencies, always use `mix hex.info <package>` to find the latest version to use.
- In controllers, use `assign_prop/3` to assign props to the Inertia page and then `render_inertia/2` to render Inertia pages.
- When generating migrations, use `mix ecto.gen.migration <name>`
- Use plural form for context modules (e.g., "Users" for users table)
- Use singular form for schema modules (e.g., "User" for users table)
- Context files are usually inside a folder named after the resource (e.g., lib/my_app/users.ex)
- Schema files are usually inside a folder named after the resource (e.g., lib/my_app/users/user.ex)
- Prefer keyword-based queries over pipe-based queries
 - For example, use `from(u in User, where: u.age > 18, select: u)` over `User |> where(age: 18) |> select([u], u)`
- Use `dbg/1` to debug code. Add `|> dbg` entries around the error area to narrow the source

## Data Structure & Type Safety

- **Always verify struct patterns**: Use explicit pattern matching like `%Reactor.Step{} = step` to ensure correct data types
- **Understand library data structures**: Before working with external library data (e.g., Reactor), verify the actual structure (lists vs maps, field names)
- **Handle argument structures correctly**: When working with step arguments, remember they are lists of `%Reactor.Argument{}` structs, not maps
- **Use appropriate functions**: Use `length/1` for lists, `map_size/1` for maps - don't mix them up
- **Check User struct fields**: User struct uses `external_id` field (from Auth0), not `id` - always use `user.external_id` for user identification

## Types

- For all data structures exchanged via API endpoints, define them using Ecto.EmbeddedSchema and Ecto.Changeset for robust runtime casting and validation of incoming data.
- Alongside every Ecto.EmbeddedSchema definition, meticulously write corresponding Elixir typespecs (@type t :: %__MODULE__{...}).
- Define all core internal application data structures using TypedStruct.
- When needed, implement explicit transformation functions to map validated data between external-facing Ecto.EmbeddedSchema and internal TypedStruct representations, maintaining a clear boundary.

## Workflows

- Use [Reactor](https://hexdocs.pm/reactor/getting-started-with-reactor.html) to create composable workflows like LLM agent/worflows or other workflows that forms process DAG.
- Split each reactor and step into its own module. Organize them into into non-hierarchical folders `steps` and `reactors` (for better composability)
- Use the DSL behaviors to create reactor and steps. Always define the inputs of the reactors, and precisely define the arguments used by each steps.
- Always wrap the step `run` implementation with `try do .. rescue` logging the stacktrace of unexpected errors and reraising it.
- RunStepError indicates an error within the implemented `run`  function in that step, sprikle `dbg` around to narrow down the source of the error
- Use the context to pass read-only data through the steps
- **Centralize shared utilities**: When building reactors, create shared utility middleware modules to avoid code duplication

## LLM

- Use [Instructor](https://hexdocs.pm/instructor/Instructor.html) for get structured outputs from LLMs
- Alawys use Ecto.Schema and use Instructor to defined the structured outputs

# LiveState Usage

- Use [LiveState](https://hexdocs.pm/live_state/) for real-time communication between frontend and backend
- **LiveState channels work differently from regular Phoenix channels**:
  - Prefer `{:noreply, state}` pattern if no follow livestate event is needed
  - Use `handle_message/2` to receive PubSub messages, not `handle_info/2`
  - Subscribe to PubSub topics in `init/3` for real-time updates
- **Frontend integration**:
  - Use "fire-and-forget" pattern: call `pushEvent()` without `await` for immediate UI response
  - Don't expect responses from events - LiveState works through state updates
  - Real-time updates come through state changes, not event responses
- **Container pattern**:
  - Create container components that manage LiveState socket creation
  - Pass sockets as props to child components
  - Follow existing patterns: `SessionListContainer`, `GameContainer`, etc.
- **State-driven navigation**:
  - Use state changes to trigger automatic navigation (e.g., job completion → session access)
  - Track processed events to prevent navigation loops when users navigate back
  - Use local component state to debounce automatic actions
- **Real-time UI principles**:
  - Avoid manual refresh buttons when LiveState provides automatic updates
  - Trust LiveState for real-time updates - remove redundant refresh mechanisms
  - State changes should immediately reflect in UI without user intervention

# React Usage

- Pages are in assets/js/pages. Use default export for pages.
- Components are in assets/js/components. Use named exports for components.
- Utils are in assets/js/lib.
- Use relative imports (e.g., `../hooks/use-something`) rather than absolute paths with `@/` to avoid build issues
- Always create the mobile version of the component along with the desktop version.
- Use kebab-case for file names.
- If the page or component uses a type for a resource from the database, like users or courses, create the type in the assets/js/types folder.
- Prefer types over interfaces.

# Testing

- Using mimic to provide mocking if need, but avoid mocking unless really needed.
- Always mock external APIs and assume the test environment runs in an isolated sandbox

## Refactoring Best Practices

- **Test continuously during refactoring**: Run `mix test` frequently during large refactoring to catch issues early
- **Use real execution for integration tests**: When testing middleware/behavior systems, use actual library execution (e.g., `Reactor.run/2`) rather than mocking the underlying system
- **Verify function arity changes**: When changing function signatures, ensure all callers are updated correctly
- **Batch similar changes**: Use sed commands for repetitive updates, but verify and fix any malformed results

# General Usage

- Use the `mix test && mix check` command after generating lots of changes to check the Elixir and React code for errors and code quality. If you encounter format errors, use `mix format` to fix them.
- If any of my requests are not clear, ask me to clarify.
- If you have better suggestions, feel free to suggest them.

# Important Lessons Learned

## LiveState vs Phoenix Channels
- **Never mix LiveState patterns with regular Phoenix channel patterns**
- LiveState channels require `{:noreply, state}` - using `{:reply, response, state}` causes `push_event/2` function errors
- Frontend should use "fire-and-forget" for immediate UI feedback, with real-time updates via state changes

## Real-time Architecture
- Use PubSub for broadcasting updates between backend processes
- Subscribe to PubSub in LiveState channel `init/3` for real-time updates
- Enhanced Job context functions to broadcast status changes for seamless real-time experience

## Frontend Build Configuration
- Avoid complex alias configurations (`@/`) - use relative imports to prevent build issues
- ESBuild plugins can be tricky to configure correctly - prefer simple, explicit paths

## Job Architecture Pattern

- **Scalable job organization**: Use job-specific context modules (`Area51.Jobs.MysteryGenerationJob`) instead of a monolithic `Area51.Jobs` module
- **Data layer separation**: Place Ecto schemas and queries in `Area51.Data.Jobs.*` with embedded data access functions
- **Loosely coupled telemetry**: Use behavior pattern (`Area51.Jobs.JobHandler`) for job-specific telemetry handlers
- **Registry-based dispatch**: Generic `ObanTelemetryHandler` dispatches to job-specific handlers via `@job_handlers` list
- **Adding new job types**: Only requires creating new context module, telemetry handler, data schema, and adding to registry - zero modification of existing jobs
- **Self-contained handlers**: Each job type implements `JobHandler` behavior and handles its own telemetry events (`handle_job_start/1`, `handle_job_completion/2`, `handle_job_failure/2`, `handle_job_exception/4`)

## Job-to-Session Integration Pattern

- **Unified creation workflows**: Use job-based systems for all entity creation to ensure consistency and async processing
- **Automatic session creation**: Workers should create persistent entities (like game sessions) after successful job completion
- **Multi-channel broadcasting**: Use PubSub to broadcast completion events to multiple channels:
  - Job management channels for progress tracking
  - Session list channels for real-time UI updates
  - Include entity IDs in completion broadcasts for frontend handling
- **Session access integration**: Completed jobs should automatically make created entities accessible in recent files/lists

## LiveState Navigation Patterns

- **Automatic navigation from job completion**: Use job completion events to trigger automatic entity access
- **Navigation loop prevention**: Track processed entity IDs in component state to prevent infinite navigation loops
- **State-driven UX**: Let job completion automatically guide user to created content while maintaining ability to navigate back
- **Cross-channel coordination**: Job management and entity list channels should coordinate for seamless user experience

# OpenTelemetry Tracing

- **Comprehensive distributed tracing** is implemented across the entire application stack
- **LiveState channel tracing**:
  - Each channel creates a span in `init/3` that lives for the channel's lifetime
  - Individual events are wrapped in child spans with proper attributes
  - Always end spans in `terminate/2` callback for proper cleanup
  - Pass OpenTelemetry context through socket assigns (`otel_span_ctx`)
- **Reactor workflow tracing**:
  - Reactors inherit external context via `otel_span_ctx` option in `Reactor.run/3`
  - OpenTelemetryMiddleware creates parent-child span relationships
  - Each step execution is automatically traced with detailed attributes
- **Context propagation patterns**:
  - LiveState channels → Agent functions → Reactor workflows → Individual steps
  - Use `otel_span_ctx: span_ctx` option to pass context between layers
  - Always attach context before creating child spans for proper hierarchy
- **Observability infrastructure**:
  - Use `docker-compose.observability.yml` for full stack (Tempo, Grafana, Prometheus, Loki)
  - Use `docker-composer.jaeger.yml` for simple Jaeger-only setup
  - Traces export to OTLP endpoints on ports 4317 (gRPC) and 4318 (HTTP)

# important-instruction-reminders
Do what has been asked; nothing more, nothing less.
NEVER create files unless they're absolutely necessary for achieving your goal.
ALWAYS prefer editing an existing file to creating a new one.
NEVER proactively create documentation files (*.md) or README files. Only create documentation files if explicitly requested by the User.
NEVER start the `mix phx.server` from the code agent. The server is normally already running, try to access it. If you cant ask me to start it.
